<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models">
  <meta name="keywords" content="Text-to-Image Generation, Controllable Diffusion Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models</h1>
          <h1 class="title is-3">arXiv 2023</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://shihaozhaozsh.github.io/">Shihao Zhao</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.dongdongchen.bid/">Dongdong Chen</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Gptgy4YAAAAJ&hl=zh-TW">Yen-Chun Chen</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://jianminbao.github.io/">Jianmin Bao</a><sup>3</sup>,</span>
			      <span class="author-block">
              <a href="https://haoosz.github.io/">Shaozhe Hao</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=k9TsUVsAAAAJ&hl=zh-CN">Lu Yuan</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://i.cs.hku.hk/~kykwong/">Kwan-Yee K. Wong</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The University of Hong Kong,</span>
			      <span class="author-block"><sup>2</sup>Microsoft Cloud AI,</span>
            <span class="author-block"><sup>3</sup>Microsoft Research Asia</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2212.08070"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://github.com/ShihaoZhaoZSH/Uni-ControlNet"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Teaser. -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div>
        <img src="./static/images/teaser.png" alt="teaser" class="center">
      </div>
      <h2 class="subtitle has-text">
        <span class="dnerf">Uni-ControlNet</span>, an approach that allows for the simultaneous utilization of different local controls and global controls in a flexible and composable manner within one model.
      </h2>

    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
  <!-- <div class="container"> -->

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-four-fifths"> -->
      <div class="column is-full-width">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
Text-to-Image diffusion models have made tremendous progress over the past two years, enabling the generation of highly realistic images based on open-domain text descriptions. However, despite their success, text descriptions often struggle to adequately convey detailed controls, even when composed of long and complex texts. Moreover, recent studies have also shown that these models face challenges in understanding such complex texts and generating the corresponding images. Therefore, there is a growing need to enable more control modes beyond text description. In this paper, we introduce Uni-ControlNet, a novel approach that allows for the simultaneous utilization of different local controls (e.g., edge maps, depth map, segmentation masks) and global controls (e.g., CLIP image embeddings) in a flexible and composable manner within one model. Unlike existing methods, Uni-ControlNet only requires the fine-tuning of two additional adapters upon frozen pre-trained text-to-image diffusion models, eliminating the huge cost of training from scratch. Moreover, thanks to some dedicated adapter designs, Uni-ControlNet only necessitates a constant number (i.e., 2) of adapters, regardless of the number of local or global controls used. This not only reduces the fine-tuning costs and model size, making it more suitable for real-world deployment, but also facilitate composability of different conditions. Through both quantitative and qualitative comparisons, Uni-ControlNet demonstrates its superiority over existing methods in terms of controllability, generation quality and composability.
          </p>
        </div>
        <img src="./static/images/comparison_table.png" alt="comparison_table" style="width:70%; ">
        <div text-align:center>
          <p class="center">
           Comparisons of different controllable diffusion models. N is the number of conditions.
          </p>
        </div>
      </div>
    </div>

    <!-- Pipeline. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <br />
        <h2 class="title is-3">Pipeline</h2>
          <img src="./static/images/pipeline1.png" alt="pipeline1" style="width:70%; ">
        <div class="content has-text-justified">
          <p>
             Uni-ControlNet categorizes various conditions into two distinct groups: local conditions and global conditions. Accordingly, two additional adapters are added: local control adapter and global control adapter.
          </p>
        </div>
        <img src="./static/images/pipeline2.png" alt="pipeline2" style="width:70%; ">
        <div class="content has-text-justified">
          <p>
           For local controls, we introduce a multi-scale condition injection strategy that uses a shared local condition encoder adapter. And for global controls, we employ another shared global condition encoder to convert them into conditional tokens, which are then concatenated with text tokens. These two adapters can be separately trained without the need of additional joint training.
          </p>
        </div>

      </div>
    </div>


    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="container is-max-desktop">
        <br />
        <h2 class="title is-3">More Results</h2>

        <img src="./static/images/more_results_single.png" alt="more_results_single" style="width:70%; ">
        <div text-align:center>
          <p class="center">
           More visual results of Uni-ControlNet for single condition setting.
          </p>
        </div>
        <img src="./static/images/more_results_multi.png" alt="more_results_multi" style="width:70%; ">
        <div text-align:center>
          <p class="center">
           More visual results of Uni-ControlNet for multi-conditions setting.
          </p>
        </div>

      </div>
    </div>

  </div>
</section>



<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{wang2022nerf,
  title={NeRF-Art: Text-Driven Neural Radiance Fields Stylization},
  author={Wang, Can and Jiang, Ruixiang and Chai, Menglei and He, Mingming and Chen, Dongdong and Liao, Jing},
  journal={arXiv preprint arXiv:2212.08070},
  year={2022}
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">

    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>

  </div>
</footer>

</body>
</html>
